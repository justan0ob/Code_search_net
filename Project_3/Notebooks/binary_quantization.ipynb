{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d3a6450",
   "metadata": {},
   "source": [
    "# Binary Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ac031",
   "metadata": {},
   "source": [
    "# Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "sys.path.append('../')\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from src.model_evaluation import evaluation\n",
    "from src.other_function import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499dc48e",
   "metadata": {},
   "source": [
    "# creating the object of evaluation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_object=evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9424a4",
   "metadata": {},
   "source": [
    "# creating the object of other functions class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb3be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_object=functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70fce6d",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c11434b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"..//Data/processed_data.csv\")\n",
    "\n",
    "\n",
    "list_data = df['tokenized_docstring'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d601a2",
   "metadata": {},
   "source": [
    "# Loading the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b120d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries=pd.read_csv(\"..//Data/query.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f57c4d",
   "metadata": {},
   "source": [
    "# Loading the model to be quantized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4839757d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/msaqib/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f16ba",
   "metadata": {},
   "source": [
    "# Loading the embeddings saved in local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8707d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=np.load(\"..//embeddings/embeddings_all_mpnet_base_v2.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa271e",
   "metadata": {},
   "source": [
    "# doing binary quantization on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab644147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: int8\n",
      "Size in bytes: 87462912\n"
     ]
    }
   ],
   "source": [
    "# all the values that are less than 0 converted to -1 and greater or equal to 0 are converted to 1\n",
    "binary_embeddings = np.where(embeddings >= 0, 1, -1).astype(np.int8)\n",
    "\n",
    "# Check if the dtype is int8 and size is 256 bytes\n",
    "print(\"Data type:\", binary_embeddings.dtype)\n",
    "print(\"Size in bytes:\", binary_embeddings.nbytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f82610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of binary embeddings is 83.41 in MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of binary embeddings is {(binary_embeddings.nbytes)/(1024*1024):.2f} in MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb57e3",
   "metadata": {},
   "source": [
    "# generating the response on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9158a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# order in which column of databse will be present\n",
    "column_order = ['Query', 'Docstrings', 'Code','Match']\n",
    "\n",
    "#creating the dataframe for model_1 which consists of for particular query all top code and\n",
    "#match column shows whether it is correctly retrieved or not\n",
    "binary_emb_query_response=pd.DataFrame(columns=column_order)\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    #getting the particular query from queries \n",
    "    query=queries.loc[i].Questions\n",
    "    \n",
    "    # getting the table dataframe that consists of docstring and code \n",
    "    #that has top match with query using cosine similarity\n",
    "    table=eval_object.get_top_code_and_docstring(query,binary_embeddings,model,list_data,df)\n",
    "    \n",
    "    #adding the column query with all values as \n",
    "    table=add_column(table,query)\n",
    "    \n",
    "    #adding columns Match that defines whether the code for given query is correctly retrieved or not\n",
    "    table=add_column(table,'Match')\n",
    "    \n",
    "    #reordering the table for better view\n",
    "    table=reorder_columns(table)\n",
    "    \n",
    "    #iterating in the table\n",
    "    for index,row in table.iterrows():\n",
    "        \n",
    "        #fetching the current code for query\n",
    "        result = row['Code']\n",
    "        \n",
    "        #getting the response from claude api\n",
    "        response=eval_object.check_response(query,row['Code'])\n",
    "    \n",
    "        #Checking the value present in the response generated by the claude\n",
    "        if 'YES' in response.content:\n",
    "            response='YES'\n",
    "        else :\n",
    "            response='NO'\n",
    "            \n",
    "        #Giving the value of response in match column for current row\n",
    "        table.at[index,'Match']=response\n",
    "    \n",
    "    #merging the table dataframe and model_1_query_response in single dataframe\n",
    "    binary_emb_query_response= pd.concat([binary_emb_query_response, table], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae5aa2",
   "metadata": {},
   "source": [
    "# MAP for binary quantized embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "795d6243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 (mean average precision) of model_3 : 63.859649122807014\n"
     ]
    }
   ],
   "source": [
    "total_yes_model_3 = (binary_emb_query_response['Match'] == 'YES').sum()\n",
    "total_no_model_3 = (binary_emb_query_response['Match'] == 'NO').sum()\n",
    "\n",
    "print(f\"MAP@10 (mean average precision) of model_3 : {(total_yes_model_3/(total_yes_model_3+total_no_model_3))*100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd44a402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
