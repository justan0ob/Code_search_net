{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c552a3d",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c9019d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/msaqib/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6adccb",
   "metadata": {},
   "source": [
    "# Importing loading_data class from data_loader.py and evaluation class from model_evaluation.py  in the src folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed562173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the current working directory \n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# getting the parent directory of the current working directory\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# Constructing a path to the \"Data\" directory located inside a directory named \"src\"\n",
    "src_data_directory = os.path.join(parent_directory, \"src\", \"Data\")\n",
    "\n",
    "src_model_directory = os.path.join(parent_directory, \"src\", \"model\")\n",
    "\n",
    "# allowing Python to search for modules in this directory.\n",
    "sys.path.append(src_data_directory)\n",
    "sys.path.append(src_model_directory)\n",
    "\n",
    "#Importing the data_preprocessor class from the data_cleaner module located in the src -> Data.\n",
    "from data_loader import loading_data\n",
    "\n",
    "#Importing the evaluation class from the model_evaluation module located in the src -> model.\n",
    "from model_evaluation import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2db39",
   "metadata": {},
   "source": [
    "# Creating an object of loading_data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f33195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_loader.loading_data at 0x15417ec90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_object=loading_data()\n",
    "\n",
    "#checking object is created and getting the address of it\n",
    "load_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c617a",
   "metadata": {},
   "source": [
    "# Creating an object of evaluation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3e992f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model_evaluation.evaluation at 0x154221150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_object=evaluation()\n",
    "\n",
    "#checking object is created and getting the address of it\n",
    "eval_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab0724",
   "metadata": {},
   "source": [
    "# Loading all Embeddings  from Models folder using loading_data class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d03ae66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the path where we have saved the embeddings of model_1\n",
    "model_1_path =load_object.get_file_path(\"embeddings_all_mpnet_base_v2.npy\",\"Models\")\n",
    "\n",
    "#Loading the embeddings of model_1 in notebook\n",
    "embeddings_model_1 = np.load(model_1_path)\n",
    "\n",
    "#getting the path where we have saved the embeddings of model_2\n",
    "model_2_path =load_object.get_file_path(\"embeddings_multilingual_e5_large_instruct.npy\",\"Models\")\n",
    "\n",
    "#Loading the embeddings of model_2 in notebook\n",
    "embeddings_model_2 = np.load(model_2_path)\n",
    "\n",
    "#getting the path where we have saved the embeddings of model_3\n",
    "model_3_path =load_object.get_file_path(\"embeddings_intfloat_e5_base_v2.npy\",\"Models\")\n",
    "\n",
    "#Loading the embeddings of model_3 in notebook\n",
    "embeddings_model_3 = np.load(model_3_path)\n",
    "\n",
    "#getting the path where we have saved the embeddings of model_4\n",
    "model_4_path =load_object.get_file_path(\"embeddings_mixedbread_ai_mxbai_embed_2d_large_v1.npy\",\"Models\")\n",
    "\n",
    "#Loading the embeddings of model_4 in notebook\n",
    "embeddings_model_4 = np.load(model_4_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48b09f",
   "metadata": {},
   "source": [
    "# Loading all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228395f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/msaqib/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "model_1 = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "model_2 = SentenceTransformer('intfloat/multilingual-e5-large-instruct')\n",
    "\n",
    "model_3 = SentenceTransformer('intfloat/e5-base-v2')\n",
    "\n",
    "model_4=SentenceTransformer(\"mixedbread-ai/mxbai-embed-2d-large-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa59968",
   "metadata": {},
   "source": [
    "# Loading the processed_data and converting into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "112cd503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the path of processed data\n",
    "processed_file_path=load_object.get_file_path(\"processed_data.csv\",\"Data\")\n",
    "\n",
    "# reading the processed_data\n",
    "df=pd.read_csv(processed_file_path)\n",
    "\n",
    "# converting the tokenized_docstring into list\n",
    "list_data = df['tokenized_docstring'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f985f93",
   "metadata": {},
   "source": [
    "# Loading the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8e21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_path=load_object.get_file_path(\"query.csv\",\"Data\",\"testing_data\")\n",
    "queries=pd.read_csv(query_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29bcbf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13aabe8",
   "metadata": {},
   "source": [
    "# Key for using Claude API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac6c3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key will be provided by the you here for using the claude api\n",
    "key='Claude_api_key'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca5f2a",
   "metadata": {},
   "source": [
    "# function for checking the response form the Claude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c63a73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_response(Questions, top_match_code):\n",
    "    \n",
    "    # converting the top_match_code in the dataframe\n",
    "    data=pd.DataFrame(top_match_code)\n",
    "    \n",
    "    # Questions is the response from the human for the claude\n",
    "    human =Questions\n",
    "    \n",
    "    # Initialize the ChatAnthropic object\n",
    "    chat = ChatAnthropic(anthropic_api_key=key ,temperature=0, model_name=\"claude-3-opus-20240229\")\n",
    "\n",
    "    # Defining system message with task description and data\n",
    "    system = (\n",
    "    \"\"\" Your task is to provide a response of only 'YES' if there is a 75 percentage matching of human input in the data,\n",
    "        or only 'No' if there isn't,\n",
    "        when comparing the data to human input.\n",
    "        \n",
    "    data: {data}\n",
    "    human: {human}\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Creating the ChatPromptTemplate\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\",human)])\n",
    "\n",
    "    # Creating the chain combining prompt and chat\n",
    "    chain = prompt | chat\n",
    "    \n",
    "    # Invoking the chain with data and human input\n",
    "    response=chain.invoke(\n",
    "    {\n",
    "         \"data\": data,\n",
    "        \"human\": human,\n",
    "    }\n",
    "    )\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5070d",
   "metadata": {},
   "source": [
    "# Evaluting the model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9df0206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "content='YES'\n",
      "2\n",
      "content='YES'\n",
      "3\n",
      "content='YES'\n",
      "4\n",
      "content='YES'\n",
      "5\n",
      "content='YES'\n",
      "6\n",
      "content='No'\n",
      "7\n",
      "content='No'\n",
      "8\n",
      "content='YES'\n",
      "9\n",
      "content='NO'\n",
      "10\n",
      "content='YES'\n",
      "11\n",
      "content='YES'\n",
      "12\n",
      "content='YES'\n",
      "13\n",
      "content='NO'\n",
      "14\n",
      "content='NO'\n",
      "15\n",
      "content='YES'\n",
      "16\n",
      "content='YES'\n",
      "17\n",
      "content='YES'\n",
      "18\n",
      "content='No'\n",
      "19\n",
      "content='YES'\n",
      "20\n",
      "content='YES'\n",
      "21\n",
      "content='YES'\n",
      "22\n",
      "content='YES'\n",
      "23\n",
      "content='YES'\n",
      "24\n",
      "content='NO'\n",
      "25\n",
      "content='YES'\n",
      "26\n",
      "content='YES'\n",
      "27\n",
      "content='YES'\n",
      "28\n",
      "content='YES'\n",
      "29\n",
      "content='YES'\n",
      "30\n",
      "content='YES'\n",
      "31\n",
      "content='YES'\n",
      "32\n",
      "content='YES'\n",
      "33\n",
      "content='YES'\n",
      "34\n",
      "content='YES'\n",
      "35\n",
      "content='YES'\n",
      "36\n",
      "content='YES'\n",
      "37\n",
      "content='YES'\n",
      "38\n",
      "content='YES'\n",
      "39\n",
      "content='YES'\n",
      "40\n",
      "content='YES'\n",
      "41\n",
      "content='YES'\n",
      "42\n",
      "content='YES'\n",
      "43\n",
      "content='YES'\n",
      "44\n",
      "content='YES'\n",
      "45\n",
      "content='YES'\n",
      "46\n",
      "content='YES'\n",
      "47\n",
      "content='YES'\n",
      "48\n",
      "content='YES'\n",
      "49\n",
      "content='No'\n",
      "50\n",
      "content='No'\n",
      "51\n",
      "content='YES'\n",
      "52\n",
      "content='YES'\n",
      "53\n",
      "content='YES'\n",
      "54\n",
      "content='YES'\n",
      "55\n",
      "content='NO'\n",
      "56\n",
      "content='YES'\n",
      "57\n",
      "content='YES'\n"
     ]
    }
   ],
   "source": [
    "# Taking count of how many yes is generated by claude api for embeddings of model_1\n",
    "yes_model_1=0\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    #getting the query \n",
    "    query=queries.loc[i].Questions\n",
    "    \n",
    "    # getting the top 10 code that matches with embeddings of query and embeddings of docstring of model\n",
    "    top_10_code=eval_object.get_top_10_code(query,embeddings_model_1,model_1,list_data,df)\n",
    "    print(i+1)\n",
    "    \n",
    "    # printing the reponse from the claude api using the key\n",
    "    print(check_response(query,top_10_code))\n",
    "    \n",
    "    # increasing the count only if the response from the claude is \"YES\"\n",
    "    if 'YES' in check_response(query,top_10_code).content:\n",
    "        yes_model_1+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ec624",
   "metadata": {},
   "source": [
    "# Evaluating the model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54f2b015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "content='No'\n",
      "2\n",
      "content='YES'\n",
      "3\n",
      "content='YES'\n",
      "4\n",
      "content='No'\n",
      "5\n",
      "content='YES'\n",
      "6\n",
      "content='YES'\n",
      "7\n",
      "content='No'\n",
      "8\n",
      "content='YES'\n",
      "9\n",
      "content='NO'\n",
      "10\n",
      "content='NO'\n",
      "11\n",
      "content='YES'\n",
      "12\n",
      "content='YES'\n",
      "13\n",
      "content='NO'\n",
      "14\n",
      "content='No'\n",
      "15\n",
      "content='YES'\n",
      "16\n",
      "content='YES'\n",
      "17\n",
      "content='YES'\n",
      "18\n",
      "content='YES'\n",
      "19\n",
      "content='YES'\n",
      "20\n",
      "content='No'\n",
      "21\n",
      "content='YES'\n",
      "22\n",
      "content='YES'\n",
      "23\n",
      "content='No'\n",
      "24\n",
      "content='YES'\n",
      "25\n",
      "content='YES'\n",
      "26\n",
      "content='YES'\n",
      "27\n",
      "content='No'\n",
      "28\n",
      "content='YES'\n",
      "29\n",
      "content='YES'\n",
      "30\n",
      "content='YES'\n",
      "31\n",
      "content='YES'\n",
      "32\n",
      "content='YES'\n",
      "33\n",
      "content='YES'\n",
      "34\n",
      "content='YES'\n",
      "35\n",
      "content='YES'\n",
      "36\n",
      "content='YES'\n",
      "37\n",
      "content='YES'\n",
      "38\n",
      "content='YES'\n",
      "39\n",
      "content='YES'\n",
      "40\n",
      "content='YES'\n",
      "41\n",
      "content='YES'\n",
      "42\n",
      "content='YES'\n",
      "43\n",
      "content='YES'\n",
      "44\n",
      "content='YES'\n",
      "45\n",
      "content='YES'\n",
      "46\n",
      "content='YES'\n",
      "47\n",
      "content='No'\n",
      "48\n",
      "content='YES'\n",
      "49\n",
      "content='No'\n",
      "50\n",
      "content='No'\n",
      "51\n",
      "content='YES'\n",
      "52\n",
      "content='YES'\n",
      "53\n",
      "content='YES'\n",
      "54\n",
      "content='YES'\n",
      "55\n",
      "content='NO'\n",
      "56\n",
      "content='YES'\n",
      "57\n",
      "content='YES'\n"
     ]
    }
   ],
   "source": [
    "# Taking count of how many yes is generated by claude api for embeddings of model_2\n",
    "yes_model_2=0\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    #getting the query \n",
    "    query=queries.loc[i].Questions\n",
    "    \n",
    "    # getting the top 10 code that matches with embeddings of query and embeddings of docstring of model\n",
    "    top_10_code=eval_object.get_top_10_code(query,embeddings_model_2,model_2,list_data,df)\n",
    "    \n",
    "    print(i+1)\n",
    "    \n",
    "    # printing the reponse from the claude api using the key\n",
    "    print(check_response(query,top_10_code))\n",
    "    \n",
    "    # increasing the count only if the response from the claude is \"YES\"\n",
    "    if 'YES' in check_response(query,top_10_code).content:\n",
    "        yes_model_2+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6d8b8",
   "metadata": {},
   "source": [
    "# Evaluating the model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eab26d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "content='YES'\n",
      "2\n",
      "content='YES'\n",
      "3\n",
      "content='YES'\n",
      "4\n",
      "content='No'\n",
      "5\n",
      "content='YES'\n",
      "6\n",
      "content='No'\n",
      "7\n",
      "content='No'\n",
      "8\n",
      "content='YES'\n",
      "9\n",
      "content='NO'\n",
      "10\n",
      "content='YES'\n",
      "11\n",
      "content='YES'\n",
      "12\n",
      "content='YES'\n",
      "13\n",
      "content='NO'\n",
      "14\n",
      "content='NO'\n",
      "15\n",
      "content='YES'\n",
      "16\n",
      "content='YES'\n",
      "17\n",
      "content='YES'\n",
      "18\n",
      "content='NO'\n",
      "19\n",
      "content='YES'\n",
      "20\n",
      "content='YES'\n",
      "21\n",
      "content='YES'\n",
      "22\n",
      "content='YES'\n",
      "23\n",
      "content='YES'\n",
      "24\n",
      "content='YES'\n",
      "25\n",
      "content='YES'\n",
      "26\n",
      "content='YES'\n",
      "27\n",
      "content='YES'\n",
      "28\n",
      "content='YES'\n",
      "29\n",
      "content='NO'\n",
      "30\n",
      "content='YES'\n",
      "31\n",
      "content='YES'\n",
      "32\n",
      "content='YES'\n",
      "33\n",
      "content='YES'\n",
      "34\n",
      "content='YES'\n",
      "35\n",
      "content='YES'\n",
      "36\n",
      "content='YES'\n",
      "37\n",
      "content='YES'\n",
      "38\n",
      "content='YES'\n",
      "39\n",
      "content='YES'\n",
      "40\n",
      "content='YES'\n",
      "41\n",
      "content='YES'\n",
      "42\n",
      "content='YES'\n",
      "43\n",
      "content='YES'\n",
      "44\n",
      "content='YES'\n",
      "45\n",
      "content='YES'\n",
      "46\n",
      "content='YES'\n",
      "47\n",
      "content='YES'\n",
      "48\n",
      "content=\"Here is a Python function to detect if a file is in CSV format:\\n\\ndef is_csv_file(file_path):\\n    try:\\n        with open(file_path, 'r') as file:\\n            sample = file.read(1024)  # Read a sample of the file\\n            \\n            # Check if the sample contains common CSV delimiters\\n            has_comma = ',' in sample\\n            has_semicolon = ';' in sample\\n            has_tab = '\\\\t' in sample\\n            \\n            # Check if the sample contains newline characters\\n            has_newline = '\\\\n' in sample or '\\\\r\\\\n' in sample\\n            \\n            # Check if the file has a .csv extension\\n            has_csv_extension = file_path.lower().endswith('.csv')\\n            \\n            return (has_comma or has_semicolon or has_tab) and has_newline and has_csv_extension\\n    \\n    except IOError:\\n        return False\\n\\nThis function does the following:\\n\\n1. It takes the file path as input.\\n\\n2. It opens the file in read mode and reads a sample of the file (in this case, the first 1024 bytes). Reading a sample instead of the entire file is more efficient, especially for large files.\\n\\n3. It checks if the sample contains common CSV delimiters such as comma (,), semicolon (;), or tab (\\\\t). The presence of these delimiters suggests that the file might be in CSV format.\\n\\n4. It checks if the sample contains newline characters (\\\\n or \\\\r\\\\n), which are typically used to separate rows in a CSV file.\\n\\n5. It checks if the file has a .csv extension, which is a common convention for CSV files.\\n\\n6. If the sample contains any of the common CSV delimiters, has newline characters, and the file has a .csv extension, the function returns True, indicating that the file is likely in CSV format. Otherwise, it returns False.\\n\\n7. If an IOError occurs while opening or reading the file, the function returns False, indicating that the file cannot be accessed or read.\\n\\nNote that this function performs a basic detection based on common characteristics of CSV files. However, it's not foolproof and may not cover all possible variations of CSV files. For more robust CSV detection, you can use libraries like csv or pandas, which provide more advanced functionality for handling CSV files.\"\n",
      "49\n",
      "content='No'\n",
      "50\n",
      "content='No'\n",
      "51\n",
      "content='YES'\n",
      "52\n",
      "content='YES'\n",
      "53\n",
      "content='YES'\n",
      "54\n",
      "content='YES'\n",
      "55\n",
      "content='NO'\n",
      "56\n",
      "content='YES'\n",
      "57\n",
      "content='YES'\n"
     ]
    }
   ],
   "source": [
    "# Taking count of how many yes is generated by claude api for embeddings of model_3\n",
    "yes_model_3=0\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    #getting the query\n",
    "    query=queries.loc[i].Questions\n",
    "    \n",
    "    # getting the top 10 code that matches with embeddings of query and embeddings of docstring of model\n",
    "    top_10_code=eval_object.get_top_10_code(query,embeddings_model_3,model_3,list_data,df)\n",
    "    print(i+1)\n",
    "    \n",
    "    # printing the reponse from the claude api using the key\n",
    "    print(check_response(query,top_10_code))\n",
    "    \n",
    "    # increasing the count only if the response from the claude is \"YES\"\n",
    "    if 'YES' in check_response(query,top_10_code).content:\n",
    "        yes_model_3+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac7d9e",
   "metadata": {},
   "source": [
    "# Evaluating the model_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bfd7255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "content='YES'\n",
      "2\n",
      "content='YES'\n",
      "3\n",
      "content='YES'\n",
      "4\n",
      "content='YES'\n",
      "5\n",
      "content='YES'\n",
      "6\n",
      "content='YES'\n",
      "7\n",
      "content='YES'\n",
      "8\n",
      "content='YES'\n",
      "9\n",
      "content='NO'\n",
      "10\n",
      "content='YES'\n",
      "11\n",
      "content='No'\n",
      "12\n",
      "content='YES'\n",
      "13\n",
      "content='YES'\n",
      "14\n",
      "content='No'\n",
      "15\n",
      "content='YES'\n",
      "16\n",
      "content='YES'\n",
      "17\n",
      "content='YES'\n",
      "18\n",
      "content='YES'\n",
      "19\n",
      "content='YES'\n",
      "20\n",
      "content='YES'\n",
      "21\n",
      "content='YES'\n",
      "22\n",
      "content='YES'\n",
      "23\n",
      "content='No'\n",
      "24\n",
      "content='YES'\n",
      "25\n",
      "content='YES'\n",
      "26\n",
      "content='YES'\n",
      "27\n",
      "content='YES'\n",
      "28\n",
      "content='YES'\n",
      "29\n",
      "content='YES'\n",
      "30\n",
      "content='YES'\n",
      "31\n",
      "content='YES'\n",
      "32\n",
      "content='NO'\n",
      "33\n",
      "content='YES'\n",
      "34\n",
      "content='YES'\n",
      "35\n",
      "content='YES'\n",
      "36\n",
      "content='YES'\n",
      "37\n",
      "content='YES'\n",
      "38\n",
      "content='YES'\n",
      "39\n",
      "content='NO'\n",
      "40\n",
      "content='YES'\n",
      "41\n",
      "content='YES'\n",
      "42\n",
      "content='YES'\n",
      "43\n",
      "content='YES'\n",
      "44\n",
      "content='YES'\n",
      "45\n",
      "content='YES'\n",
      "46\n",
      "content='YES'\n",
      "47\n",
      "content='YES'\n",
      "48\n",
      "content='YES'\n",
      "49\n",
      "content='YES'\n",
      "50\n",
      "content='No'\n",
      "51\n",
      "content='YES'\n",
      "52\n",
      "content='YES'\n",
      "53\n",
      "content='YES'\n",
      "54\n",
      "content='YES'\n",
      "55\n",
      "content='NO'\n",
      "56\n",
      "content='YES'\n",
      "57\n",
      "content='YES'\n"
     ]
    }
   ],
   "source": [
    "# Taking count of how many yes is generated by claude api for embeddings of model_4\n",
    "yes_model_4=0\n",
    "for i in range(len(queries)):\n",
    "    #getting the query\n",
    "    query=queries.loc[i].Questions\n",
    "    \n",
    "    # getting the top 10 code that matches with embeddings of query and embeddings of docstring of model\n",
    "    top_10_code=eval_object.get_top_10_code(query,embeddings_model_4,model_4,list_data,df)\n",
    "    print(i+1)\n",
    "    \n",
    "    # printing the reponse from the claude api using the key\n",
    "    print(check_response(query,top_10_code))\n",
    "    \n",
    "    # increasing the count only if the response from the claude is \"YES\"\n",
    "    if 'YES' in check_response(query,top_10_code).content:\n",
    "        yes_model_4+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a2863d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "43\n",
      "45\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(yes_model_1)\n",
    "print(yes_model_2)\n",
    "print(yes_model_3)\n",
    "print(yes_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24974e2e",
   "metadata": {},
   "source": [
    "# Accuracy for model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fa2ce5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_1 : 78.94736842105263\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of model_1 : {(yes_model_1/len(queries))*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60402e28",
   "metadata": {},
   "source": [
    "# Accuracy for model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2acc84cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_2 : 75.43859649122807\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of model_2 : {(yes_model_2/len(queries))*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1f585",
   "metadata": {},
   "source": [
    "# Accuracy for model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71b225c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_3 : 78.94736842105263\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of model_3 : {(yes_model_3/len(queries))*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b4cb3",
   "metadata": {},
   "source": [
    "# Accuracy for model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "812b71c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model_4 : 87.71929824561403\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy of model_4 : {(yes_model_4/len(queries))*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2c8692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
